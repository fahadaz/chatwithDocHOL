{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "name": "Title",
    "collapsed": false
   },
   "source": "# ❄️ Snowflake Chat with your Documents Notebook ❄️"
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "Flow",
    "collapsed": false,
    "codeCollapsed": false
   },
   "source": "# Import necessary functions\nimport streamlit as st\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n# Define image in a stage and read the file\nimage=session.file.get_stream(\"@TALK_TO_DOC.PUBLIC.PDFDOCS/pdf/RAG_flow.png\" , decompress=False).read() \n\n# Display the image\nst.image(image, width=800)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "Libraries",
    "collapsed": false
   },
   "source": "import snowflake.snowpark as snowpark\n\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\nsession.use_database('TALK_TO_DOC')\nsession.use_schema('PUBLIC')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "64842e12-1e4c-423b-a568-376102123485",
   "metadata": {
    "language": "sql",
    "name": "ViewStage",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- List files in the stage to identify PDFs\nLS @TALK_TO_DOC.PUBLIC.PDFDOCS;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f293bf7-06b5-4d05-9666-ad3096d25a31",
   "metadata": {
    "language": "sql",
    "name": "CreateParsedTextTable",
    "collapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE TALK_TO_DOC.PUBLIC.PARSED_TEXT (relative_path VARCHAR(500), raw_text VARIANT);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f3f037e-63a8-495e-a814-b90933270e05",
   "metadata": {
    "language": "sql",
    "name": "ExtractTextWith_Parse_Document",
    "collapsed": false
   },
   "outputs": [],
   "source": "Insert Into TALK_TO_DOC.PUBLIC.PARSED_TEXT (relative_path, raw_text)\nwith pdf_files (relative_path)\nAS\n(SELECT distinct\n        METADATA$FILENAME AS relative_path           \n        FROM @TALK_TO_DOC.PUBLIC.PDFDocs\n    WHERE METADATA$FILENAME ILIKE '%.pdf')\n\n\nSELECT relative_path, SNOWFLAKE.CORTEX.PARSE_DOCUMENT(\n                '@TALK_TO_DOC.PUBLIC.PDFDOCS',\n                relative_path,\n                OBJECT_CONSTRUCT('mode', 'LAYOUT') \n            ) as raw_text\n    from pdf_files    \n;    ",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "71c4ee0b-afad-4ab8-a80f-7760b9d74359",
   "metadata": {
    "name": "ExtractText_old",
    "collapsed": true
   },
   "source": "from snowflake.snowpark.functions import col, to_variant\n\n# Query to fetch distinct PDF files from the stage\nfiles_df = session.sql(\"\"\"\n    SELECT DISTINCT METADATA$FILENAME AS file_name\n    FROM @HOL.PUBLIC.PDF\n    WHERE METADATA$FILENAME ILIKE '%.pdf'\n\"\"\").collect()\n\n# Loop through the distinct filenames and parse if not already in the target table\nfor row in files_df:\n    file_name = row['FILE_NAME']\n    \n    # Check if the file has already been parsed\n    check_df = session.table(\"PARSED_TEXT\").filter(col(\"relative_path\") == file_name).select(\"relative_path\").collect()\n\n    # If not already parsed, proceed to parse and insert the text\n    if not check_df:\n        # Extract raw text using the PARSE_DOCUMENT function\n        parse_result = session.sql(f\"\"\"\n            SELECT SNOWFLAKE.CORTEX.PARSE_DOCUMENT(\n                '@HOL.PUBLIC.PDF',\n                '{file_name}',\n                OBJECT_CONSTRUCT('mode', 'OCR')\n            ) AS raw_text\n        \"\"\").collect()\n        \n        # Ensure parse_result contains data before proceeding\n        if parse_result:\n            # Get the parsed raw text and cast it to VARIANT\n            raw_text = parse_result[0]['RAW_TEXT']\n            \n            # Create DataFrame with explicit VARIANT type for raw_text\n            df_to_insert = session.create_dataframe(\n                [(file_name, raw_text)],\n                schema=[\"relative_path\", \"raw_text\"]\n            ).select(\n                col(\"relative_path\"),\n                to_variant(col(\"raw_text\")).alias(\"raw_text\")  # Explicitly cast to VARIANT\n            )\n            \n            # Insert the DataFrame into the PARSED_TEXT table\n            df_to_insert.write.mode(\"append\").save_as_table(\"PARSED_TEXT\")\n\nprint(\"PDF files parsed successfully.\")"
  },
  {
   "cell_type": "code",
   "id": "71fc5ddc-33ae-40d9-a36e-49de52d35de2",
   "metadata": {
    "language": "sql",
    "name": "ViewParsedData",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT RELATIVE_PATH, RAW_TEXT FROM TALK_TO_DOC.PUBLIC.PARSED_TEXT LIMIT 5;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4469e412-b254-4e86-9c21-075bf9b25aef",
   "metadata": {
    "language": "python",
    "name": "CreateTextChunker",
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark.types import StructType, StructField, StringType\nimport pandas as pd\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# Define the text chunker class\nclass text_chunker:\n\n    def process(self, text):        \n        text_raw = []\n        text_raw.append(text) \n        \n        text_splitter = RecursiveCharacterTextSplitter(\n            separators=[\"\\n\"],  # Define an appropriate separator. New line is good typically!\n            chunk_size=800,     # Adjust this as you see fit\n            chunk_overlap=100,    # This lets text have some form of overlap. Useful for keeping chunks contextual\n            length_function=len,\n            add_start_index=True  # Optional but useful if you'd like to feed the chunk before/after\n        )\n    \n        chunks = text_splitter.create_documents(text_raw)\n        \n        # Adjust DataFrame creation to match schema (chunk, meta)\n        chunk_texts = [chunk.page_content.encode('utf-8', 'ignore').decode('utf-8') for chunk in chunks]\n        metas = [str(chunk.metadata) for chunk in chunks]\n        \n        df = pd.DataFrame({\n            'chunk': chunk_texts,\n            'meta': metas\n        })\n        \n        yield from df.itertuples(index=False, name=None)\n\n# Register the UDTF\nschema = StructType([\n     StructField(\"chunk\", StringType()),\n     StructField(\"meta\", StringType()),\n ])\n\nsession.udtf.register( \n    handler=text_chunker,\n    output_schema=schema, \n    input_types=[StringType()], \n    is_permanent=True, \n    name='CHUNK_TEXT', \n    replace=True, \n    packages=['pandas', 'langchain'], \n    stage_location='@TALK_TO_DOC.PUBLIC.PDFDOCS'\n)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "74855c60-d81e-4e47-87cf-8a41c6bc0ad1",
   "metadata": {
    "name": "backupcode",
    "collapsed": true
   },
   "source": "-- Create the chunked version of your parsed text\nCREATE OR REPLACE TABLE TALK_TO_DOC.PUBLIC.CHUNK_TEXT AS\n    SELECT\n        raw.relative_path,\n        build_scoped_file_url('@TALK_TO_DOC.PUBLIC.PDFDOCS', raw.relative_path) AS file_url,\n        CONCAT(raw.RAW_TEXT:content::string, ': ', func.chunk) AS chunk,\n        'English' AS language,\n        func.meta AS meta_info\n    FROM\n        TALK_TO_DOC.PUBLIC.PARSED_TEXT AS raw,\n        TABLE(TALK_TO_DOC.PUBLIC.CHUNK_TEXT(TO_VARCHAR(raw.raw_text:content::string))) AS func;"
  },
  {
   "cell_type": "code",
   "id": "d018fc83-2563-432e-8c69-598069fe57b3",
   "metadata": {
    "language": "sql",
    "name": "ChunkParsedText",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Create the chunked version of your parsed text\nCREATE OR REPLACE TABLE TALK_TO_DOC.PUBLIC.CHUNK_TEXT AS\n    SELECT\n        raw.relative_path,\n        build_scoped_file_url('@TALK_TO_DOC.PUBLIC.PDFDOCS', raw.relative_path) AS file_url,\n        CONCAT(raw.relative_path, ': ', func.chunk) AS chunk,\n        'English' AS language,\n        func.meta AS meta_info\n    FROM\n        TALK_TO_DOC.PUBLIC.PARSED_TEXT AS raw,\n        TABLE(TALK_TO_DOC.PUBLIC.CHUNK_TEXT(TO_VARCHAR(raw.raw_text:content))) AS func;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "00570c35-4b44-48c7-8586-eaaa7bebda52",
   "metadata": {
    "language": "sql",
    "name": "ViewChunkedText",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT RELATIVE_PATH, CHUNK, META_INFO FROM TALK_TO_DOC.PUBLIC.CHUNK_TEXT limit 30;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "de7d1d70-dcd5-4284-a6c2-85f2c2739186",
   "metadata": {
    "language": "sql",
    "name": "GrantCortexAccessDB",
    "collapsed": false
   },
   "outputs": [],
   "source": "GRANT DATABASE ROLE SNOWFLAKE.CORTEX_USER TO ROLE accountadmin;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "44a330f9-c774-47f2-b8ca-031ae441c602",
   "metadata": {
    "language": "sql",
    "name": "CreateCortexSearchService",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Create a search service over your new chunked pdf table\nCREATE OR REPLACE CORTEX SEARCH SERVICE TALK_TO_DOC.PUBLIC.TEXT_SEARCH_SERVICE\n    ON CHUNK\n    ATTRIBUTES LANGUAGE\n    WAREHOUSE = COMPUTE_WH\n    TARGET_LAG = '7 days'\n    AS (\n    SELECT\n        CHUNK,\n        RELATIVE_PATH,\n        LANGUAGE\n    FROM TALK_TO_DOC.PUBLIC.CHUNK_TEXT\n    );",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "821543ad-e73e-4c52-929e-e04ca0186d3b",
   "metadata": {
    "language": "python",
    "name": "CheckSearchService",
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark import Session\nfrom snowflake.core import Root\nroot = Root(session)\n\ntranscript_search_service = (root\n  .databases['TALK_TO_DOC']\n  .schemas['PUBLIC']\n  .cortex_search_services['TEXT_SEARCH_SERVICE']\n)\n\nresp = transcript_search_service.search(\n  query=\"\"\"What is Cortex Search and how is it helpful for a RAG application?\"\"\",\n  columns=['CHUNK'],\n  limit=3\n)\n\nst.json(resp.to_json())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cbcba381-2cbf-4ff9-91b5-133453b3d476",
   "metadata": {
    "language": "python",
    "name": "ViewSearchResults",
    "collapsed": false
   },
   "outputs": [],
   "source": "results = resp.results\n\ncontext_str = \"\"\nfor i, r in enumerate(results):\n    context_str += f\"Context document {i+1}: {r['CHUNK']}\\n****************\\n\"\n\nprint(context_str)\ndf = session.create_dataframe(resp.results)\ndf.create_or_replace_temp_view(\"searchresults\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5faba3d3-75a5-4058-b8b1-065bc66e81a0",
   "metadata": {
    "language": "sql",
    "name": "ExplainWithCortexComplete",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT SNOWFLAKE.CORTEX.COMPLETE(\n    'mistral-large',\n    CONCAT(\n        'You are a helpful AI assistant specialized in retrieving information from documents. ',\n        'The internal user has asked the following question: <results>',\n        (SELECT LISTAGG(CHUNK, ' ') FROM searchresults),\n        '</results> ',\n        'Based on the context provided between the <context> and </context> tags, generate a coherent, concise, and relevant answer to the question. Focus on the key points and avoid unnecessary details. '\n    )\n) AS CRITIQUE\nFROM searchresults\nLIMIT 1;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "26870615-a19d-4da2-a7a4-5ee6d59cc448",
   "metadata": {
    "name": "QACustomizedModel",
    "collapsed": false
   },
   "source": "# Next Step:\n\nPlease create the associated \"Chat with your Documents\" SiS app. This will allow users to interactively leverage the Cortex Search RAG.\n\nOnce users have saved sufficient questions and customized/corrected answers via the SiS app, return to this Snowflake Notebook to create a customized fine-tuned Cortex model.\n"
  },
  {
   "cell_type": "code",
   "id": "c693d9c4-ca51-4c73-b143-6f9cc77dc19b",
   "metadata": {
    "language": "sql",
    "name": "SplitQAForModeling",
    "collapsed": false
   },
   "outputs": [],
   "source": "ALTER TABLE QA_TABLE\nADD COLUMN source VARCHAR;\nUPDATE QA_TABLE\nSET\n  source = CASE\n    WHEN RANDOM () <= 0.7 THEN 'train'\n    ELSE 'validation'\n  END;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2ddb221f-e6d3-4cde-9385-25bc6f94acba",
   "metadata": {
    "language": "sql",
    "name": "ViewFineTuningTrainingData",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT RAGQUESTION, RAGANSWER, source FROM QA_TABLE LIMIT 5;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "803467a8-c97d-4cec-9c77-2b96f0907fa0",
   "metadata": {
    "language": "sql",
    "name": "CreateFineTunedModel",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT SNOWFLAKE.CORTEX.FINETUNE (\n    'CREATE',\n    'custom_QA_model',\n    'mistral-7b',\n    'SELECT RAGQUESTION as prompt, RAGANSWER as completion FROM QA_TABLE WHERE source = \\'train\\'',\n    'SELECT RAGQUESTION as prompt, RAGANSWER as completion FROM QA_TABLE WHERE source = \\'validation\\''\n  );",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9a28ae1b-60cd-42df-bb15-237b8cafef5f",
   "metadata": {
    "name": "UseCustomizedModel",
    "collapsed": false
   },
   "source": "# Next Step:\n\nReturn to the \"Chat with your Documents\" SiS App. \n\nUpdate lines 12 to 17, with this code to include your customized_QA_model:\n\n```\nENABLED_CUSTOM_QA_MODELS = True\n\nMODELS = [\n    \"mistral-large\",\n    \"snowflake-arctic\",\n    \"llama3-70b\",\n    \"llama3-8b\",\n    \"customized_QA_model\"\n]\n\nif ENABLED_CUSTOM_QA_MODELS:\n    MODELS.append( \"customized_QA_model\")\n```\n\nNow update lines 80 to 110, with an updated def init_config_options function. This will provide a checkbox for the user to select to use their custom model.:\n\n```\ndef init_config_options():\n    st.sidebar.selectbox(\n        \"Select Cortex Search Service:\",\n        [s[\"name\"] for s in st.session_state.service_metadata],\n        key=\"selected_cortex_search_service\",\n    )\n\n    clear_button_clicked = st.sidebar.button(\"Clear conversation\")\n    if clear_button_clicked:\n        st.session_state.clear_conversation = True\n        init_session_state()\n\n    use_chat_history = st.sidebar.checkbox(\n        \"Use chat history\", value=st.session_state.use_chat_history\n    )\n    st.session_state.use_chat_history = use_chat_history\n\n    with st.sidebar.expander(\"Advanced options\"):\n        st.selectbox(\"Select model:\", MODELS, key=\"model_name\")\n        st.number_input(\n            \"Select number of context chunks\",\n            key=\"num_retrieved_chunks\",\n            min_value=1,\n            max_value=10,\n        )\n        st.number_input(\n            \"Select number of messages to use in chat history\",\n            key=\"num_chat_messages\",\n            min_value=1,\n            max_value=10,\n        )\n        use_custom_model = False\n        if ENABLED_CUSTOM_QA_MODELS:\n            # Add a checkbox to use customized Q&A model\n            use_custom_model = st.checkbox(\"Use customized Q&A model\", key=\"use_customized_qa_model\")\n```\n\nNow at line 144 to 145, update the complete function to use the customized_QA_model if the use selects the \"Use customized model\" checkbox.\n```\ndef complete(model, prompt):\n    # Use customized Q&A model if selected\n    if st.session_state.get(\"use_customized_qa_model\", False):\n        model = \"customized_QA_model\"\n    return Complete(model, prompt).replace(\"$\", \"\\$\")\n```\n\nFinally, select the \"Run\" button for your new code to be used and test your update application. Remember to look in the sidebar \"Advanced options\" to check the \"Use customized Q&A model\" when testing new questions. Uncheck the checkbox \"Use chat history\""
  }
 ]
}